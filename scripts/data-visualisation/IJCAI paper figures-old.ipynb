{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7606356",
   "metadata": {},
   "source": [
    "# Generate Figures for IJCAI paper "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc262e",
   "metadata": {},
   "source": [
    "**Paper:** *Solving the Identifying Code Set Problem with Independent Support*\n",
    "\n",
    "**By:** Anna L.D. Latour, Arunabha Sen, Kuldeep S. Meel\n",
    "    \n",
    "**Venue:** IJCAI 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f436e4",
   "metadata": {},
   "source": [
    "### Research questions\n",
    "\n",
    "We generate the figures for four main research questions:\n",
    "\n",
    "**Q1**: How many instances are solved by `FindGIS` and `PBPBS`?\n",
    "\n",
    "**Q2**: How do the solving times of `FindGIS` and `PBPBS` scale with $k$ and $|V|$?\n",
    "\n",
    "**Q3**: How does the model size of the CNF encoding scale with $k$ and $|V|$?\n",
    "\n",
    "**Q4**: How do the solution qualities of `FindGIS` and `PBPBS` compare?\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Make sure that the following environment variables are defined:\n",
    "\n",
    "- `LOCAL_PROJECT_DIR`: the directory with all the project code.\n",
    "- `DATA_DIR`: the directory to store all the raw output files from the experiments, as well as the json files obtained after parsing.\n",
    "\n",
    "Also, the following scripts need to be run in order to generate json files with experimental data, obtained from parsing the raw output files from the experiments:\n",
    "\n",
    "```bash\n",
    "user@machine:~$ cd $LOCAL_PROJECT_DIR/scripts/data-analysis\n",
    "user@machine data-analysis$ python parse_files.py --expid IC26 --enctype gis --data_dir $DATA_DIR\n",
    "user@machine data-analysis$ python parse_files.py --expid IC27 --enctype ilp --data_dir $DATA_DIR\n",
    "user@machine data-analysis$ python collect_network_stats.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf92be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally useful packages:\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Packages for manipulating data:\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil, floor, log, sqrt\n",
    "from scipy.optimize import least_squares\n",
    "from statistics import median, mean\n",
    "\n",
    "# Packages for making figures (that look good):\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend import Legend\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper script for processing json files with results:\n",
    "LOCAL_PROJECT_DIR = os.getenv('PROJECT_DIR')\n",
    "sys.path.insert(1, f'../data-analysis')\n",
    "from data_aggregator import DataAggregator\n",
    "sys.path.insert(1, f'../helpers')\n",
    "import tolatex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca22d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helpful directories:\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "JSON_DIR = f'{DATA_DIR}/exp-data'\n",
    "NETWORK_DIR = f'{DATA_DIR}/instances/networks'\n",
    "STATS_DIR = f'{DATA_DIR}/exp-data/network-stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a5de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_png = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85490d4c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6716e9",
   "metadata": {},
   "source": [
    "###### Define the scope\n",
    "\n",
    "We will generate figures and tables for both the GIS and the ILP pipeline.\n",
    "\n",
    "**IC26**: GIS pipeline.\n",
    "\n",
    "**IC27**: ILP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d475f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment IDs\n",
    "gis_expid = 'IC26'\n",
    "ilp_expid = 'IC27'\n",
    "\n",
    "# Subdirectories in which the networks are stored\n",
    "networktypes = [\n",
    "    'crime', \n",
    "    'geometric',\n",
    "    'infrastructure', 'power', 'road', 'webgraph',\n",
    "    'collaboration', 'social'\n",
    "]\n",
    "\n",
    "# Values for maximum identifiable set size\n",
    "k_values = ['1', '2', '3', '4', '6', '8', '10', '12', '16']\n",
    "\n",
    "# ILP encoding configurations\n",
    "ilp_configs = [\n",
    "    'config0',   # No optimisations\n",
    "    'config1'    # Remove supersets\n",
    "]\n",
    "# No choice in configuration for GIS pipeline, because we didn't implement any\n",
    "\n",
    "# JSON fields for the encoding step\n",
    "enc_fields = {\n",
    "    'output_header': ['benchmark', 'network_type', 'encoding', 'configuration'],\n",
    "    'encoding_details': ['k'],\n",
    "    'network_data': ['n_nodes', 'n_edges'],\n",
    "    \n",
    "    'timeout_info': ['utime', 'max_res_set_size', 'exit_status'],\n",
    "  }\n",
    "\n",
    "# JSON fields for the solving step\n",
    "fields = {\n",
    "    'output_header': [\n",
    "        'benchmark', 'network_type',\n",
    "        'encoding', 'configuration',\n",
    "        'timeout', 'memory_limit'\n",
    "    ],\n",
    "    'encoding_details': ['k', 'encoding_t/o', 'building_successful', 'encoding_successful'],\n",
    "    'network_data': ['n_nodes', 'n_edges'],\n",
    "    'timeout_info': [\n",
    "        'utime', 'stime', 'wtime',\n",
    "        'max_res_set_size',\n",
    "        'exit_status', 'signal'\n",
    "    ],\n",
    "    'solution_info': [\n",
    "        'optimised_value',\n",
    "#         'k'\n",
    "    ]\n",
    "}\n",
    "ilp_fields = {\n",
    "    'ilp_data': ['n_vars', 'n_csts'],\n",
    "    'cplex_info': [\n",
    "        'solution_time',\n",
    "        'deterministic_time',\n",
    "        'memout',\n",
    "        'all_rows_eliminated_during_preprocessing',\n",
    "        'n_rows', 'n_non_zeros', 'n_binaries'\n",
    "    ]\n",
    "}\n",
    "ilp_fields.update(fields)\n",
    "ilp_fields['output_header'].append('configuration')\n",
    "\n",
    "gis_fields = {\n",
    "    'cnf_data': ['n_vars', 'n_clauses', 'n_groups', 'n_Avars'],\n",
    "    'arjun_info': ['arjun_time']\n",
    "}\n",
    "gis_fields.update(fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfbd9a",
   "metadata": {},
   "source": [
    "### Define experimental parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2481c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 7200\n",
    "memout = 4000000   # 4 GB\n",
    "\n",
    "penalty_factor = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673aa6a",
   "metadata": {},
   "source": [
    "### Specify the relevant networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d56e9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant networks: 50\n",
      "Number of relevant social networks: 32\n",
      "Number of relevant grid networks: 18\n"
     ]
    }
   ],
   "source": [
    "# The file with relevant networks contains the networks that we consider for the\n",
    "# experiments. They are selected as real-world networks of varying sizes that\n",
    "# do not contain any errors in their encoding.\n",
    "\n",
    "relevant_networks = []\n",
    "relevant_network_file = f'{LOCAL_PROJECT_DIR}/scripts/data-analysis/relevant_networks.txt'\n",
    "with open(relevant_network_file, 'r') as infile:\n",
    "    relevant_networks = [line.replace('.gz\\n', '') for line in infile.readlines()]\n",
    "print(\"Number of relevant networks:\", len(relevant_networks))\n",
    "\n",
    "relevant_networks_social = []\n",
    "relevant_networks_social_file = f'{LOCAL_PROJECT_DIR}/scripts/data-analysis/relevant_networks_social.txt'\n",
    "with open(relevant_networks_social_file, 'r') as infile:\n",
    "    relevant_networks_social = [line.replace('.gz\\n', '') for line in infile.readlines()]\n",
    "print(\"Number of relevant social networks:\", len(relevant_networks_social))\n",
    "\n",
    "relevant_networks_grid = []\n",
    "relevant_networks_grid_file = f'{LOCAL_PROJECT_DIR}/scripts/data-analysis/relevant_networks_grids.txt'\n",
    "with open(relevant_networks_grid_file, 'r') as infile:\n",
    "    relevant_networks_grid = [line.replace('.gz\\n', '') for line in infile.readlines()]\n",
    "print(\"Number of relevant grid networks:\", len(relevant_networks_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88117f8",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "### Load the data\n",
    "\n",
    "We first identify and load all the relevant datasets. Here is a description of the experiment IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "780bb332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n",
      "PhilippineAdj.txt.gcnf.gz.json.gz\n",
      "ParisAdj.txt.gcnf.gz.json.gz\n",
      "MadridAdj.txt.gcnf.gz.json.gz\n",
      "ZerkaniAdj.txt.gcnf.gz.json.gz\n",
      "soccer_ball.txt.gcnf.gz.json.gz\n",
      "inf-USAir97.mtx.gcnf.gz.json.gz\n",
      "power-494-bus.mtx.gcnf.gz.json.gz\n",
      "power-eris1176.mtx.gcnf.gz.json.gz\n",
      "power-bcspwr09.mtx.gcnf.gz.json.gz\n",
      "power-685-bus.mtx.gcnf.gz.json.gz\n",
      "power-1138-bus.mtx.gcnf.gz.json.gz\n",
      "power-US-Grid.mtx.gcnf.gz.json.gz\n",
      "road-euroroad.edges.gcnf.gz.json.gz\n",
      "road-roadNet-PA.mtx.gcnf.gz.json.gz\n",
      "road-luxembourg-osm.mtx.gcnf.gz.json.gz\n",
      "road-chesapeake.mtx.gcnf.gz.json.gz\n",
      "road-minnesota.mtx.gcnf.gz.json.gz\n",
      "web-EPA.edges.gcnf.gz.json.gz\n",
      "web-webbase-2001.mtx.gcnf.gz.json.gz\n",
      "web-edu.mtx.gcnf.gz.json.gz\n",
      "web-indochina-2004.mtx.gcnf.gz.json.gz\n",
      "web-spam.mtx.gcnf.gz.json.gz\n",
      "ca-CondMat.mtx.gcnf.gz.json.gz\n",
      "ca-GrQc.mtx.gcnf.gz.json.gz\n",
      "ca-citeseer.mtx.gcnf.gz.json.gz\n",
      "ca-Erdos992.mtx.gcnf.gz.json.gz\n",
      "ca-dblp-2010.mtx.gcnf.gz.json.gz\n",
      "ca-sandi_auths.mtx.gcnf.gz.json.gz\n",
      "ca-netscience.mtx.gcnf.gz.json.gz\n",
      "socfb-Simmons81.mtx.gcnf.gz.json.gz\n",
      "socfb-Williams40.mtx.gcnf.gz.json.gz\n",
      "socfb-Swarthmore42.mtx.gcnf.gz.json.gz\n",
      "socfb-Pepperdine86.mtx.gcnf.gz.json.gz\n",
      "socfb-Haverford76.mtx.gcnf.gz.json.gz\n",
      "soc-dolphins.mtx.gcnf.gz.json.gz\n",
      "socfb-nips-ego.edges.gcnf.gz.json.gz\n",
      "socfb-Hamilton46.mtx.gcnf.gz.json.gz\n",
      "socfb-Middlebury45.mtx.gcnf.gz.json.gz\n",
      "socfb-Bowdoin47.mtx.gcnf.gz.json.gz\n",
      "socfb-Vassar85.mtx.gcnf.gz.json.gz\n",
      "socfb-Trinity100.mtx.gcnf.gz.json.gz\n",
      "socfb-USFCA72.mtx.gcnf.gz.json.gz\n",
      "socfb-Oberlin44.mtx.gcnf.gz.json.gz\n",
      "socfb-Wellesley22.mtx.gcnf.gz.json.gz\n",
      "socfb-Caltech36.mtx.gcnf.gz.json.gz\n",
      "socfb-Amherst41.mtx.gcnf.gz.json.gz\n",
      "socfb-Reed98.mtx.gcnf.gz.json.gz\n",
      "socfb-Colgate88.mtx.gcnf.gz.json.gz\n",
      "socfb-Mich67.mtx.gcnf.gz.json.gz\n",
      "socfb-Smith60.mtx.gcnf.gz.json.gz\n"
     ]
    }
   ],
   "source": [
    "ilp_data = DataAggregator(\n",
    "    expid=ilp_expid, \n",
    "    json_dir=JSON_DIR,\n",
    "    encoding='ilp',\n",
    "    k_values=k_values,\n",
    "    network_types=networktypes,\n",
    "    configs=ilp_configs,\n",
    "    relevant_fields=ilp_fields\n",
    ").get_data()\n",
    "\n",
    "gis_data = DataAggregator(\n",
    "    expid=gis_expid,\n",
    "    json_dir=JSON_DIR,\n",
    "    encoding='gis',\n",
    "    k_values=k_values,\n",
    "    network_types=networktypes,\n",
    "    configs=[],\n",
    "    relevant_fields=gis_fields\n",
    ").get_data()\n",
    "\n",
    "# Only keep data for the relevant networks\n",
    "ilp_data = ilp_data[ilp_data['benchmark'].isin(relevant_networks)].copy()\n",
    "gis_data = gis_data[gis_data['benchmark'].isin(relevant_networks)].copy()\n",
    "\n",
    "# Make sure columns are of the right datatype\n",
    "ilp_data.k = ilp_data.k.astype(int)\n",
    "# gis_data.dropna(subset=['k'], inplace=True)\n",
    "gis_data.k = gis_data.k.astype(int)\n",
    "# print(gis_data.optimised_value)\n",
    "gis_data.optimised_value = gis_data.optimised_value.fillna(-1)\n",
    "gis_data.optimised_value = gis_data.optimised_value.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf0f52",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40b20df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean this up. The \"np.where()\" method is unreliable.\n",
    "\n",
    "# Identify instances that could not be encoded due to timeout or memout\n",
    "\n",
    "ilp_data['encoding_t/o'] = np.where(\n",
    "    (ilp_data.utime > 0.95*timeout) &\n",
    "    (ilp_data.max_res_set_size <= memout - 500000), \n",
    "    True, False)\n",
    "ilp_data['encoding_m/o'] = np.where(\n",
    "    (ilp_data.utime <= 0.95*timeout) &\n",
    "    (ilp_data.max_res_set_size > memout - 500000),\n",
    "    True, False)\n",
    "\n",
    "gis_data['encoding_t/o'] = np.where(\n",
    "    gis_data.exit_status == 124,\n",
    "    True, False)\n",
    "gis_data['encoding_m/o'] = np.where(\n",
    "    (~gis_data['encoding_t/o']) &\n",
    "    (gis_data.max_res_set_size > memout - 500000),\n",
    "    True, False)\n",
    "\n",
    "# Identify instances that could not be solved due to timeout, memout or other errors\n",
    "\n",
    "# ilp_data['solving_t/o'] = np.where(\n",
    "#     (ilp_data.utime_solve > 0.95*sol_timeout) &\n",
    "#     (ilp_data.max_res_set_size_solve <= sol_memout - 500000), \n",
    "#     True, False)\n",
    "# ilp_data['solving_m/o'] = np.where(\n",
    "#     (ilp_data.utime_solve <= 0.95*sol_timeout) &\n",
    "#     (ilp_data.max_res_set_size_solve > sol_memout - 500000),\n",
    "#     True, False)\n",
    "\n",
    "# gis_data['solving_m/o'] = np.where(\n",
    "#     (gis_data.exit_status_solve == 1),\n",
    "#     True, False)\n",
    "# gis_data['solving_t/o'] = np.where(\n",
    "#     (gis_data.exit_status_solve == 124),\n",
    "#     True, False)\n",
    "# gis_data['other_error'] = np.where(\n",
    "#     (gis_data.exit_status_solve.isin([134, 139])),\n",
    "#      True, False)\n",
    "\n",
    "\n",
    "# # TODO PHASE OUT THE FOLLOWING\n",
    "# # Introduce helper columns that indicate timeouts and memouts\n",
    "# # NOTE: there seems to be a problem with the logging of the (un)succesfull encoding reporting, \n",
    "# # so the following is unreliable.\n",
    "# ilp_enc_data.loc[\n",
    "#     ilp_enc_data.building_successful &\n",
    "# #     ~ilp_enc_data.encoding_successful &\n",
    "#     (ilp_enc_data.utime > 0.95*enc_timeout) &\n",
    "#     (ilp_enc_data.max_res_set_size <= enc_memout - 500000), 'encoding_t/o'\n",
    "# ] = True\n",
    "# ilp_enc_data.loc[\n",
    "#     ilp_enc_data.building_successful &\n",
    "#     ~ilp_enc_data.encoding_successful &\n",
    "#     (ilp_enc_data.utime < enc_timeout) &\n",
    "#     (ilp_enc_data.max_res_set_size > enc_memout - 500000), 'encoding_m/o'\n",
    "# ] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb2121",
   "metadata": {},
   "source": [
    "### Store data\n",
    "\n",
    "We simply save the data as `.csv` files, so it's a bit easier to inspect the data, if you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db8a1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_data.sort_values(['configuration', 'benchmark', 'k'], inplace=True)\n",
    "ilp_data.to_csv(f'{ilp_expid}_ilp-data_ijcai.csv')\n",
    "\n",
    "gis_data.sort_values(['config', 'benchmark', 'k'], inplace=True)\n",
    "gis_data.to_csv(f'{gis_expid}_gis-data_ijcai.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad155cea",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6cd36",
   "metadata": {},
   "source": [
    "### Aesthetics (for figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 2\n",
    "\n",
    "col_width_in = 3.375  # According to IJCAI 2022 guidelines\n",
    "col_gap_in = 0.25     # According to IJCAI 2022 guidelines\n",
    "textwidth_in = 2*col_width_in + col_gap_in \n",
    "\n",
    "col_width_pt = col_width_in*72\n",
    "\n",
    "def get_fig_height(f_width):\n",
    "    golden_mean = (sqrt(5) - 1.0) / 2.0  # Aesthetic ratio\n",
    "    return f_width * golden_mean / 1.5\n",
    "\n",
    "c_ilp = '#EE7BCA'  # hot pink\n",
    "c_timeout = '#C03251'  # red wine stain\n",
    "c_gis = '#D47E56'  # orange\n",
    "\n",
    "summerwander2 = '#8B2B90'  # purple\n",
    "summerwander4 = '#276ABE'  # strong blue\n",
    "summerwander5 = '#6CACE3'  # light strong blue\n",
    "\n",
    "style = {\n",
    "    'fail': {\n",
    "        'c': c_timeout,\n",
    "        'ls': '-',\n",
    "    },\n",
    "    'ilp-csts': {\n",
    "        'c': c_ilp,\n",
    "        'ls': '-',\n",
    "        'm': 'o'\n",
    "    },\n",
    "    'ilp-vars': {\n",
    "        'c': c_ilp,\n",
    "        'ls': '--',\n",
    "        'm': 's'\n",
    "    },\n",
    "    'gis-clss': {\n",
    "        'c': c_gis,\n",
    "        'ls': '-',\n",
    "        'm': '+'\n",
    "    },\n",
    "    'gis-vars': {\n",
    "        'c': c_ilp,\n",
    "        'ls': '--',\n",
    "        'm': 'x'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f908d8",
   "metadata": {},
   "source": [
    "### Plotting helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def isPower (x, y):\n",
    "    # From https://www.geeksforgeeks.org/check-if-a-number-is-power-of-another-number/\n",
    "\n",
    "    # The only power of 1\n",
    "    # is 1 itself\n",
    "    if (x == 1):\n",
    "        return (y == 1)\n",
    "\n",
    "    # Repeatedly compute\n",
    "    # power of x\n",
    "    pow = 1\n",
    "    while (pow < y):\n",
    "        pow = pow * x\n",
    "\n",
    "    # Check if power of x\n",
    "    # becomes y\n",
    "    return (pow == y)\n",
    "        \n",
    "def get_lower_bound(number):\n",
    "    zeros = 0\n",
    "    while number > 10:\n",
    "        number = number/10\n",
    "        zeros = zeros + 1\n",
    "    return floor(number), zeros\n",
    "\n",
    "def get_upper_bound(number):\n",
    "    zeros = 0\n",
    "    while number > 10:\n",
    "        number = number/10\n",
    "        zeros = zeros + 1\n",
    "    return ceil(number), zeros\n",
    "\n",
    "def compute_ticks_bounds(the_values):\n",
    "    ub_num, ub_zeros = get_upper_bound(max(the_values))\n",
    "    lb_num, lb_zeros = get_lower_bound(min(the_values))\n",
    "    ub = ub_num * 10**ub_zeros\n",
    "    lb = lb_num * 10**lb_zeros\n",
    "    ticks = []\n",
    "    if lb_zeros == ub_zeros:\n",
    "        ticks = range(lb, ub + 1, 10**ub_zeros)\n",
    "    elif lb_zeros == ub_zeros - 1:\n",
    "        lb = 0\n",
    "        ticks = range(lb, ub + 1, 10**ub_zeros)\n",
    "    if len(ticks) < 3:\n",
    "        ticks = range(lb, ub + 1, int(0.5 * 10 ** ub_zeros))\n",
    "    return ticks\n",
    "\n",
    "def latexify_integer(myint, group=3, char='\\\\,'):\n",
    "    if myint < 1000:\n",
    "        return str(myint)\n",
    "    else:\n",
    "        # From https://stackoverflow.com/a/30919497\n",
    "        myint_str = str(myint)\n",
    "        return ((char[::-1]).join((myint_str[::-1])[i:i+group] for i in range(0, len(myint_str), group)))[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8bf36",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "We now generate the tables presented in the main paper. Specifically, we generate tables 2 and 3, used to answer **Q1** and **Q2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb5fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def the_par(values, n_fail, val_fail, penalty_factor):\n",
    "    return float(sum(values) + n_fail * val_fail * penalty_factor)/(len(values) + n_fail)\n",
    "\n",
    "def get_par_tables_new(instances=None, penalty_factor=2, ilp_config='config1'):\n",
    "    gis_k_values = sorted(gis_data.k.unique())\n",
    "    \n",
    "    # Get data for relevant benchmarks:\n",
    "    ilp_data_inst = ilp_data[(ilp_data['benchmark'].isin(instances)) & (ilp_data.ilp_configuration == ilp_config)].copy()\n",
    "    gis_data_inst = gis_data[gis_data['benchmark'].isin(instances)].copy()\n",
    "\n",
    "    overview_table_rows = []\n",
    "    restricted_table_rows = []\n",
    "    compact_table_rows = []\n",
    "    \n",
    "    # Compute par2 and number of unsolved instances per value of k:   \n",
    "    for k in gis_k_values:\n",
    "        print(f'k = {k}')    \n",
    "        \n",
    "        gis_k_data = gis_data_inst[gis_data_inst['k'] == k].copy()\n",
    "        \n",
    "        gis_enc_timeout_rows = gis_k_data[gis_k_data['encoding_t/o']].copy()\n",
    "        gis_enc_memout_rows = gis_k_data[gis_k_data['encoding_m/o']].copy()\n",
    "        gis_enc_success_rows = gis_k_data[~gis_k_data.n_vars.isna()].copy()\n",
    "                \n",
    "        gis_sol_timeout_rows = gis_k_data[gis_k_data['solving_t/o']].copy()\n",
    "        gis_sol_memout_rows = gis_k_data[gis_k_data['solving_m/o']].copy()\n",
    "        gis_sol_error_rows = gis_k_data[gis_k_data['other_error']].copy()\n",
    "        gis_sol_success_rows = gis_k_data[gis_k_data.optimised_value > -1].copy()\n",
    "        \n",
    "        \n",
    "        ilp_k_data = ilp_data_inst[ilp_data_inst['k'] == k].copy()\n",
    "        \n",
    "        ilp_enc_timeout_rows = ilp_k_data[ilp_k_data['encoding_t/o']].copy()\n",
    "        ilp_enc_memout_rows = ilp_k_data[ilp_k_data['encoding_m/o']].copy()\n",
    "        ilp_enc_success_rows = ilp_k_data[~ilp_k_data.n_vars.isna()].copy()\n",
    "        \n",
    "        ilp_sol_timeout_rows = ilp_k_data[ilp_k_data['solving_t/o']].copy()\n",
    "        ilp_sol_memout_rows = ilp_k_data[ilp_k_data['solving_m/o']].copy()\n",
    "        ilp_sol_success_rows = ilp_k_data[~ilp_k_data.optimised_value.isna()].copy()\n",
    "        \n",
    "        \n",
    "        n_gis_enc_failure = len(gis_enc_timeout_rows.axes[0]) + len(gis_enc_memout_rows.axes[0])\n",
    "        n_ilp_enc_failure = len(ilp_enc_timeout_rows.axes[0]) + len(ilp_enc_memout_rows.axes[0])\n",
    "        n_gis_sol_failure = len(gis_sol_timeout_rows.axes[0]) + len(gis_sol_memout_rows.axes[0])\n",
    "        n_ilp_sol_failure = len(ilp_sol_timeout_rows.axes[0]) + len(ilp_sol_memout_rows.axes[0]) + len(gis_sol_error_rows.axes[0])   \n",
    "        \n",
    "        n_gis_enc_success = len(gis_enc_success_rows.axes[0])\n",
    "        n_gis_sol_success = len(gis_sol_success_rows.axes[0])\n",
    "        n_ilp_enc_success = len(ilp_enc_success_rows.axes[0])\n",
    "        n_ilp_sol_success = len(ilp_sol_success_rows.axes[0])\n",
    "        \n",
    "        if n_gis_enc_success + n_gis_enc_failure < len(gis_k_values):\n",
    "            print(\"!!! Wrong numbers !!!!\")\n",
    "            print(f'n_gis_enc_success: {n_gis_enc_success}')\n",
    "            print(f'n_gis_enc_failure: {n_gis_enc_failure}')\n",
    "            print(f'gis_k_values: {gis_k_values}')\n",
    "        if n_ilp_enc_success + n_ilp_enc_failure < len(gis_k_values):\n",
    "            print(\"!!! Wrong numbers !!!!\")\n",
    "            print(f'n_ilp_enc_success: {n_ilp_enc_success}')\n",
    "            print(f'n_ilp_enc_failure: {n_ilp_enc_failure}')\n",
    "            print(f'gis_k_values: {gis_k_values}')\n",
    "            \n",
    "        # Compute PAR2 value for encoding into CNF:\n",
    "        gis_enc_par = the_par(\n",
    "            gis_enc_success_rows.utime_enc.tolist(), \n",
    "            n_gis_enc_failure, \n",
    "            enc_timeout, penalty_factor)\n",
    "        # Compute PAR2 value for FindGIS solving the instances that could be encoded into CNF:\n",
    "        gis_sol_par = the_par(\n",
    "            gis_sol_success_rows.utime_solve.tolist(), \n",
    "            n_gis_sol_failure, \n",
    "            enc_timeout, penalty_factor)\n",
    "        # Compute PAR2 value for encoding into ILP:\n",
    "        ilp_enc_par = the_par(\n",
    "            ilp_enc_success_rows.utime_enc.tolist(), \n",
    "            n_ilp_enc_failure, \n",
    "            sol_timeout, penalty_factor)\n",
    "        # Compute PAR2 value for CPLEX solving the instances that could be encoded into ILP:\n",
    "        ilp_sol_par = the_par(\n",
    "            ilp_sol_success_rows.utime_solve.tolist(), \n",
    "            n_ilp_sol_failure, \n",
    "            sol_timeout, penalty_factor) \n",
    "\n",
    "        # Create a new column for the solving time of the entire pipeline:\n",
    "        # TODO: clean this up because \"np.where()\" is unreliable.\n",
    "        gis_k_data.utime_tot = np.where(\n",
    "            (~gis_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "            (gis_k_data.optimised_value > -1) &    # Instance was solved\n",
    "            (gis_k_data.utime_enc + gis_k_data.utime_solve <= tot_timeout),  # Total time did not exceed tot_timeout\n",
    "        gis_k_data.utime_enc + gis_k_data.utime_solve, penalty_factor * tot_timeout)\n",
    "        \n",
    "        ilp_k_data.utime_tot = np.where(\n",
    "            (~ilp_k_data.n_vars.isna()) &          # Instance was encoded\n",
    "            (~ilp_k_data.optimised_value.isna()) & # Instance was solved\n",
    "            (ilp_k_data.utime_enc + ilp_k_data.utime_solve <= tot_timeout),\n",
    "        ilp_k_data.utime_enc + ilp_k_data.utime_solve, penalty_factor * tot_timeout)\n",
    "        \n",
    "        \n",
    "        n_gis_tot_success = len(gis_k_data[gis_k_data.utime_tot <= tot_timeout].axes[0])\n",
    "        n_gis_tot_fail = len(gis_k_data[gis_k_data.utime_tot > tot_timeout].axes[0])\n",
    "        print(f'n_gis_tot_success + n_gis_tot_fail = {n_gis_tot_success} + {n_gis_tot_fail} = {n_gis_tot_success+n_gis_tot_fail}')\n",
    "\n",
    "        n_ilp_tot_success = len(ilp_k_data[ilp_k_data.utime_tot <= tot_timeout].axes[0])\n",
    "        n_ilp_tot_fail = len(ilp_k_data[ilp_k_data.utime_tot > tot_timeout].axes[0])\n",
    "        print(f'n_ilp_tot_success + n_ilp_tot_fail = {n_ilp_tot_success} + {n_ilp_tot_fail} = {n_ilp_tot_success+n_ilp_tot_fail}')\n",
    "        \n",
    "        gis_tot_par = gis_k_data.utime_tot.mean()\n",
    "        ilp_tot_par = ilp_k_data.utime_tot.mean()\n",
    "            \n",
    "        # Rows $k$, GIS (tot) and ILP (tot) are table 2 in the main paper\n",
    "        overview_table_rows.append({\n",
    "            '$k$': f'${k}$',\n",
    "            'GIS (tot)': f'${latexify_integer(int(gis_tot_par))}$ (${latexify_integer(n_gis_tot_success)}$)',\n",
    "            'ILP (tot)': f'${latexify_integer(int(ilp_tot_par))}$ (${latexify_integer(n_ilp_tot_success)}$)',\n",
    "            'GIS (encoding only)': f'${latexify_integer(int(gis_enc_par))}$ (${latexify_integer(n_gis_enc_success)}$)',\n",
    "            'GIS (solving only)': f'${latexify_integer(int(gis_sol_par))}$ (${latexify_integer(n_gis_sol_success)}$)',\n",
    "            'ILP (encoding only)': f'${latexify_integer(int(ilp_enc_par))}$ (${latexify_integer(n_ilp_enc_success)}$)',\n",
    "            'ILP (solving only)': f'${latexify_integer(int(ilp_sol_par))}$ (${latexify_integer(n_ilp_sol_success)}$)',\n",
    "        })\n",
    "        \n",
    "        # To compare the par2 values to those from the GIS method, we collect the same data for the\n",
    "        # the same instances solved by the GIS method\n",
    "        ilp_solved_instances = ilp_sol_success_rows.benchmark.unique().tolist()\n",
    "        ilp_solving_times = ilp_sol_success_rows.utime_solve.to_list()\n",
    "        ilp_par = the_par(ilp_solving_times, 0, sol_timeout, penalty_factor)\n",
    "        gis_solving_times = gis_k_data[(gis_k_data['benchmark'].isin(ilp_solved_instances))].utime_solve.to_list()\n",
    "        gis_par = the_par(gis_solving_times, 0, sol_timeout, penalty_factor)\n",
    "        \n",
    "\n",
    "        # Because the newly created column utime_tot does not work as expected, here I'm computing again the\n",
    "        # average total encoding + solving times for those instances that could be encoded by the ILP method.\n",
    "        gis_tot_utimes_restricted = [ut_enc + ut_solve \n",
    "                             if ut_enc + ut_solve <= tot_timeout\n",
    "                             else penalty_factor * tot_timeout\n",
    "                             for (ut_enc, ut_solve) \n",
    "                             in zip(\n",
    "                                 gis_k_data[\n",
    "                                     (~gis_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                                     (gis_k_data.optimised_value > -1) &    # Instance was solved\n",
    "                                     (gis_k_data.benchmark.isin(ilp_solved_instances))].utime_enc.tolist(),\n",
    "                                 gis_k_data[\n",
    "                                     (~gis_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                                     (gis_k_data.optimised_value > -1) &    # Instance was solved\n",
    "                                     (gis_k_data.benchmark.isin(ilp_solved_instances))].utime_solve.tolist()\n",
    "                                 )\n",
    "                            ]\n",
    "        print(f'Total number of instances solved by GIS = {len(gis_tot_utimes_restricted)}, ' +\n",
    "              f'average solving time = {mean(gis_tot_utimes_restricted)}')\n",
    "              \n",
    "        ilp_tot_utimes_restricted = [ut_enc + ut_solve \n",
    "                     if ut_enc + ut_solve <= tot_timeout\n",
    "                     else penalty_factor * tot_timeout\n",
    "                     for (ut_enc, ut_solve) \n",
    "                     in zip(\n",
    "                         ilp_k_data[\n",
    "                             (~ilp_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                             (~ilp_k_data.optimised_value.isna()) &    # Instance was solved\n",
    "                             (ilp_k_data.benchmark.isin(ilp_solved_instances))].utime_enc.tolist(),\n",
    "                         ilp_k_data[\n",
    "                             (~ilp_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                             (ilp_k_data.optimised_value > -1) &    # Instance was solved\n",
    "                             (ilp_k_data.benchmark.isin(ilp_solved_instances))].utime_solve.tolist()\n",
    "                         )\n",
    "                    ]\n",
    "        print(f'Total number of instances solved by ILP = {len(ilp_tot_utimes_restricted)}, ' +\n",
    "              f'average solving time = {mean(ilp_tot_utimes_restricted)}')\n",
    "        \n",
    "        ilp_enc_utimes_restricted = [ut_enc\n",
    "             if ut_enc + ut_solve <= tot_timeout\n",
    "             else penalty_factor * tot_timeout\n",
    "             for (ut_enc, ut_solve) \n",
    "             in zip(\n",
    "                 ilp_k_data[\n",
    "                     (~ilp_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                     (~ilp_k_data.optimised_value.isna()) &    # Instance was solved\n",
    "                     (ilp_k_data.benchmark.isin(ilp_solved_instances))].utime_enc.tolist(),\n",
    "                 ilp_k_data[\n",
    "                     (~ilp_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                     (ilp_k_data.optimised_value > -1) &    # Instance was solved\n",
    "                     (ilp_k_data.benchmark.isin(ilp_solved_instances))].utime_solve.tolist()\n",
    "                 )\n",
    "            ]\n",
    "        ilp_solve_utimes_restricted = [ut_solve\n",
    "             if ut_enc + ut_solve <= tot_timeout\n",
    "             else penalty_factor * tot_timeout\n",
    "             for (ut_enc, ut_solve) \n",
    "             in zip(\n",
    "                 ilp_k_data[\n",
    "                     (~ilp_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                     (~ilp_k_data.optimised_value.isna()) &    # Instance was solved\n",
    "                     (ilp_k_data.benchmark.isin(ilp_solved_instances))].utime_enc.tolist(),\n",
    "                 ilp_k_data[\n",
    "                     (~ilp_k_data.n_vars.isna()) &          # Instnace was encoded\n",
    "                     (ilp_k_data.optimised_value > -1) &    # Instance was solved\n",
    "                     (ilp_k_data.benchmark.isin(ilp_solved_instances))].utime_solve.tolist()\n",
    "                 )\n",
    "            ]\n",
    "        ilp_enc_vs_solve = zip(ilp_enc_utimes_restricted, ilp_solve_utimes_restricted)\n",
    "        for (enc_t, solve_t) in ilp_enc_vs_solve:\n",
    "            print(f\"{enc_t}, {solve_t}\")\n",
    "              \n",
    "        # This is table 3 in the main paper, with the results restricted to those instances that could be\n",
    "        # encoded into ILP\n",
    "        restricted_table_rows.append({\n",
    "            '$k$': f'${k}$',\n",
    "            f'GIS tot mean': f'${mean(gis_tot_utimes_restricted)}$',\n",
    "            f'ILP tot mean': f'${mean(ilp_tot_utimes_restricted)}$',\n",
    "            '\\# instances': f'${latexify_integer(n_ilp_sol_success)}$',\n",
    "            f'PAR{penalty_factor} (GIS)': f'${gis_par}$',\n",
    "            f'PAR{penalty_factor} (ILP)': f'${ilp_par}$',\n",
    "        })\n",
    "\n",
    "    overview_par_results = pd.DataFrame(overview_table_rows)\n",
    "    filename_overview = f'{gis_enc_expid}_{gis_sol_expid}_{ilp_enc_expid}_{ilp_sol_expid}_par{penalty_factor}_ijcai'\n",
    "#     with open(f'{filename_overview}.tex', 'w') as tf:\n",
    "#         tf.write(overview_par_results.to_latex(index=True, escape=False))\n",
    "    with open(f'{filename_overview}_transposed.tex', 'w') as tf:\n",
    "        tf.write(overview_par_results.transpose().to_latex(index=True, escape=False))\n",
    "        \n",
    "    restricted_par_results = pd.DataFrame(restricted_table_rows)\n",
    "    filename_restricted = f'{gis_enc_expid}_{gis_sol_expid}_{ilp_enc_expid}_{ilp_sol_expid}_par{penalty_factor}_restricted_ijcai'\n",
    "#     with open(f'{filename_restricted}.tex', 'w') as tf:\n",
    "#         tf.write(restricted_par_results.to_latex(index=True, escape=False))\n",
    "    with open(f'{filename_restricted}_transposed.tex', 'w') as tf:\n",
    "        tf.write(restricted_par_results.transpose().to_latex(index=True, escape=False))\n",
    "                \n",
    "        \n",
    "get_par_tables_new(instances=relevant_networks, penalty_factor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd42dfb",
   "metadata": {},
   "source": [
    "We also check which are the largest networks that could be encoded and solved by the two methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_solved_network(instances=None, ilp_config='config1'):\n",
    "    ilp_data_inst = ilp_data[(ilp_data['benchmark'].isin(instances)) & (ilp_data.ilp_configuration == ilp_config)].copy()\n",
    "    gis_data_inst = gis_data[gis_data['benchmark'].isin(instances)].copy()\n",
    "    \n",
    "    ilp_data_encoded = ilp_data_inst[~ilp_data_inst.n_vars.isna()].copy()\n",
    "    gis_data_encoded = gis_data_inst[~gis_data_inst.n_vars.isna()].copy()\n",
    "    ilp_data_solved = ilp_data_inst[~ilp_data_inst.optimised_value.isna()].copy()\n",
    "    gis_data_solved = gis_data_inst[gis_data_inst.optimised_value > -1].copy()\n",
    "    \n",
    "    ilp_data_encoded.sort_values(['n_nodes', 'k'], inplace=True, ascending=False)\n",
    "    gis_data_encoded.sort_values(['n_nodes', 'k'], inplace=True, ascending=False)\n",
    "    ilp_data_solved.sort_values(['n_nodes', 'k'], inplace=True, ascending=False)\n",
    "    gis_data_solved.sort_values(['n_nodes', 'k'], inplace=True, ascending=False)\n",
    "    \n",
    "    print('*' * 80 + '\\nLargest networks that could be encoded into ILP:')\n",
    "    print(ilp_data_encoded[['benchmark', 'n_nodes', 'k', 'n_vars']].head(10))\n",
    "    print('*' * 80 + '\\nLargest networks that could be encoded into CNF:')\n",
    "    print(gis_data_encoded[['benchmark', 'n_nodes', 'k', 'n_vars']].head(10))\n",
    "    print('*' * 80 + '\\nLargest networks that could be solved by CPLEX:')\n",
    "    print(ilp_data_solved[['benchmark', 'n_nodes', 'k', 'optimised_value']].head(10))\n",
    "    print('*' * 80 + '\\nLargest networks that could be solved by FindGIS:')\n",
    "    print(gis_data_solved[['benchmark', 'n_nodes', 'k', 'optimised_value']].head(10))\n",
    "    \n",
    "largest_solved_network(instances=relevant_networks)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a38626",
   "metadata": {},
   "source": [
    "## Model size\n",
    "\n",
    "We now generate Figures 2 and 3 in the main paper, which visualise the model size as a function of the number of nodes in the network $|V|$ and the maximum identifiable set size $k$, used to answer **Q3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4757eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_model_size_vs_network_size(instances=None, network_size_param='n_nodes', model_size_param='n_clauses'):\n",
    "    \n",
    "    # Set up the figure\n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    fig_height =  fig_width * 0.5\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_height, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('viridis_r')\n",
    "    fitting_data = []\n",
    "\n",
    "    gis_enc_data_inst = gis_enc_data[gis_enc_data['benchmark'].isin(instances)].copy()\n",
    "    gis_enc_data_inst = gis_enc_data[gis_enc_data[model_size_param].notna()]\n",
    "\n",
    "    for k in sorted([int(k) for k in k_values]):\n",
    "        k_data = gis_enc_data_inst[gis_enc_data_inst['k'] == k].copy()\n",
    "        k_data.sort_values(network_size_param, inplace=True)\n",
    "        network_sizes = k_data[network_size_param].to_list()\n",
    "        model_sizes = k_data[model_size_param].to_list()\n",
    "\n",
    "        ax.plot(network_sizes, model_sizes,\n",
    "                color=cmap(k / 16.0), lw=0.5,\n",
    "                label=r'$k = ' + str(k) + r'$')\n",
    "\n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    if network_size_param == 'n_nodes':\n",
    "        ax.set_xlabel(r'$|V|$')\n",
    "    elif network_size_param == 'n_edges':\n",
    "        ax.set_xlabel(r'$|E|$')\n",
    "        \n",
    "    if model_size_param == 'n_clauses':\n",
    "        ax.set_ylabel(r'\\# clauses')\n",
    "    elif model_size_param == 'n_vars':\n",
    "        ax.set_ylabel(r'\\# variables')\n",
    "        \n",
    "    tolatex.format_axes(ax)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if len(instances) > 10:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.65, 0.2),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=3,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "    else:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.65, 0.2),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=3,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "\n",
    "    fig_filename = f'{gis_enc_expid}_gis_{model_size_param}_vs_{network_size_param}_ijcai'\n",
    "    plt.savefig(f\"{fig_filename}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{fig_filename}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "# This is Figure 2 in the main paper:\n",
    "plot_model_size_vs_network_size(instances=relevant_networks, model_size_param='n_clauses', network_size_param='n_nodes')\n",
    "\n",
    "# These are other figures that may be of interest:\n",
    "plot_model_size_vs_network_size(instances=relevant_networks, model_size_param='n_vars', network_size_param='n_nodes')\n",
    "plot_model_size_vs_network_size(instances=relevant_networks, model_size_param='n_clauses', network_size_param='n_edges')\n",
    "plot_model_size_vs_network_size(instances=relevant_networks, model_size_param='n_vars', network_size_param='n_edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_size_vs_k(instances=None, size_param='n_nodes'):\n",
    "    \"\"\"Plot model sizes of ILP and GIS encoding as a function of k, \n",
    "    with either n_nodes or n_edges visualised in colour.\n",
    "\n",
    "    Args:\n",
    "        instances (list): A list of instances that we want to include in the plot.\n",
    "        size_param (str): Choose from: {k, n_nodes, n_edges, median_degree}\n",
    "\n",
    "    Returns:\n",
    "        bool: The return value. True for success, False otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the figure\n",
    "    \n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    fig_height =  fig_width * 0.5\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_height, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    \n",
    "    cmap = plt.cm.get_cmap('viridis_r')\n",
    "    markers = ['x', '+', '1', '2', '3', '4']\n",
    "    \n",
    "    # Extract extreme values\n",
    "    max_n_csts = max(\n",
    "        ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)].n_csts.max(), \n",
    "        gis_enc_data[gis_enc_data['benchmark'].isin(instances)].n_clauses.max())\n",
    "    max_n_vars = max(\n",
    "        ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)].n_vars.max(), \n",
    "        gis_enc_data[gis_enc_data['benchmark'].isin(instances)].n_vars.max())\n",
    "\n",
    "\n",
    "    gis_enc_data.sort_values('n_nodes', inplace=True)\n",
    "#     benchmarks = [b for b in enc_data_gis.benchmark.unique() if b in instances]\n",
    "    \n",
    "    gis_enc_data_inst = gis_enc_data[gis_enc_data['benchmark'].isin(instances)].copy()\n",
    "    \n",
    "    numbers_of_nodes = gis_enc_data_inst.n_nodes.unique()    \n",
    "    numbers_of_edges = gis_enc_data_inst.n_edges.unique()\n",
    "    \n",
    "    max_n_nodes = max(numbers_of_nodes)\n",
    "    min_n_nodes = min(numbers_of_nodes)\n",
    "    \n",
    "    max_n_edges = max(numbers_of_edges)\n",
    "    \n",
    "    for i, instance in enumerate(instances):\n",
    "        this_inst_data = gis_enc_data_inst[gis_enc_data_inst['benchmark'] == instance].copy()\n",
    "        if this_inst_data['n_clauses'].isnull().sum() == len(this_inst_data.index):\n",
    "            continue\n",
    "        this_inst_data.sort_values('k', inplace=True)\n",
    "        k_values = this_inst_data['k'].to_list()\n",
    "        n_clauses = this_inst_data['n_clauses'].to_list()\n",
    "        n_nodes = this_inst_data['n_nodes'].unique()[0]\n",
    "        n_edges = this_inst_data['n_edges'].unique()[0]\n",
    "        scaled_n_clauses = [(1.0 * n_clause)/min(n_clauses) for n_clause in n_clauses]\n",
    "        \n",
    "        if size_param == 'n_nodes':            \n",
    "            label=r'$|V| = ' + str(int(n_nodes)) + r'$'\n",
    "            cmap_colour = n_nodes/max_n_nodes*1.0\n",
    "        elif size_param == 'n_edges':\n",
    "            label=r'$|E| = ' + str(int(n_edges)) + r'$'\n",
    "            cmap_colour = n_edges/max_n_edges*1.0\n",
    "            \n",
    "        if len(instances) > 10:                \n",
    "            ax.plot(k_values, scaled_n_clauses,\n",
    "                    color=cmap(cmap_colour), lw=0.5,\n",
    "                    label=label)\n",
    "        else:\n",
    "            ax.plot(k_values, scaled_n_clauses,\n",
    "                    color=cmap(cmap_colour), lw=0.5,\n",
    "                    label=label,\n",
    "                    marker=markers[i % len(markers)])\n",
    "\n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.set_xlabel(r'$k$')\n",
    "    ax.set_xticks([1, 2, 3, 4, 6, 8, 12, 16])\n",
    "    ax.set_yticks([1, 3, 5])\n",
    "    ax.set_ylabel(r'normalised \\# clauses')\n",
    "    tolatex.format_axes(ax)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if len(instances) > 10:\n",
    "        ax.legend(handles[::-7], labels[::-7],\n",
    "                  bbox_to_anchor=(0.35, 0.75),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=2,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "    else:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.325, 0.8),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=2,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "    figname = f\"{gis_enc_expid}_norm-n_clauses-vs-k_colour-is-{size_param}_{len(instances)}-inst_ijcai\"\n",
    "    plt.savefig(f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{figname}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "instances = ['soccer_ball.txt',\n",
    "             'inf-USAir97.mtx',\n",
    "             'socfb-Pepperdine86.mtx',\n",
    "             'ca-Erdos992.mtx',\n",
    "             'web-indochina-2004.mtx',\n",
    "             'ca-CondMat.mtx',\n",
    "             ]\n",
    "\n",
    "# This is Figure 3 in the main paper:\n",
    "plot_model_size_vs_k(instances=instances, size_param='n_nodes')\n",
    "\n",
    "# This is the same figure only we report the number of edges instead of the number of nodes:\n",
    "plot_model_size_vs_k(instances=instances, size_param='n_edges')\n",
    "\n",
    "\n",
    "# And here are the plots for all instances:\n",
    "plot_model_size_vs_k(instances=relevant_networks, size_param='n_nodes')\n",
    "plot_model_size_vs_k(instances=relevant_networks, size_param='n_edges')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a0027",
   "metadata": {},
   "source": [
    "## Solution quality\n",
    "\n",
    "We now analyse the results on the instances that could be encoded into ILP, so we can report on the relative solution qualities of the GIS method and the ILP method (**Q4**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2269cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cardinality_ratios(instances=None, ilp_config='config1'):\n",
    "    \n",
    "    # Get data for relevant benchmarks:\n",
    "    ilp_data_inst = ilp_data[(ilp_data['benchmark'].isin(instances)) & (ilp_data.ilp_configuration == ilp_config)].copy()\n",
    "    gis_data_inst = gis_data[gis_data['benchmark'].isin(instances)].copy()\n",
    "    \n",
    "    cardinality_ratios = []\n",
    "    for k in k_values:\n",
    "        ilp_solved_instances = ilp_data_inst[(ilp_data_inst.k == int(k)) & (~ilp_data_inst.optimised_value.isna())].benchmark.unique()\n",
    "        for instance in ilp_solved_instances:\n",
    "            gis_opt_val = gis_data_inst[(gis_data_inst.k == int(k)) & (gis_data_inst.benchmark == instance)].optimised_value.tolist()[0]\n",
    "            ilp_opt_val = ilp_data_inst[(ilp_data_inst.k == int(k)) & (ilp_data_inst.benchmark == instance)].optimised_value.tolist()[0]\n",
    "            cardinality_ratio = (float(gis_opt_val)/2)/ilp_opt_val\n",
    "            cardinality_ratios.append((k, instance, cardinality_ratio))\n",
    "    cardinality_ratios.sort(key = lambda x: x[2])\n",
    "    for elt in cardinality_ratios:\n",
    "        print(elt)\n",
    "    \n",
    "get_cardinality_ratios(instances=relevant_networks)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca704d5",
   "metadata": {},
   "source": [
    "## Details about benchmark set\n",
    "\n",
    "We now generate Table 4 in the technical appendix. **Important**: make sure to run `scripts/collect_network_stats.py` first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5666c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = []\n",
    "for json_file in os.listdir(STATS_DIR):\n",
    "    path_to_file = f'{STATS_DIR}/{json_file}'\n",
    "    print(path_to_file)\n",
    "    with gzip.open(path_to_file) as json_file:\n",
    "        instance_data = json.loads(json_file.read())\n",
    "        new_dict = {\n",
    "            'network': instance_data['network'].replace('.gz', ''),\n",
    "            'n_nodes': instance_data['n_nodes'],\n",
    "            'n_edges': instance_data['n_edges'],\n",
    "            'max_degree': instance_data['max_degree'],\n",
    "            'med_degree': instance_data['med_degree'],\n",
    "            'mean_degree': instance_data['mean_degree'],\n",
    "            'mean_clustering': mean(instance_data['clustering'].values()),\n",
    "            'mean_n_triangles': mean(instance_data['n_triangles'].values()),\n",
    "        }\n",
    "        aggregated_data.append(new_dict)\n",
    "        data = pd.DataFrame(aggregated_data)\n",
    "\n",
    "data = data[data['network'].isin(relevant_networks)].copy()\n",
    "data.sort_values('n_nodes', inplace=True)\n",
    "print(data)\n",
    "data.to_csv('aggregated_network_stats_ijcai.csv')\n",
    "\n",
    "compact_table_rows = []\n",
    "for index, row in data.iterrows():\n",
    "    compact_table_rows.append({\n",
    "        'network': re.sub(\"\\.(txt|mtx|edges)\\.gz\", \"\", row['network'], re.DOTALL).replace('_', '-'),\n",
    "        '$|V|$': '$' + latexify_integer(row['n_nodes']) + '$',\n",
    "        r'$|E|$': r'$' + latexify_integer(row['n_edges']) + r'$',\n",
    "        r'$med(d)$': r'$' + latexify_integer(row['med_degree']) + r'$',\n",
    "    })\n",
    "compact_results = pd.DataFrame(compact_table_rows)\n",
    "filename = f'network_stats_ijcai'\n",
    "with open(f'{filename}.tex', 'w') as tf:\n",
    "    tf.write(compact_results.to_latex(index=False, escape=False))\n",
    "with open(f'{filename}_transposed.tex', 'w') as tf:\n",
    "    tf.write(compact_results.transpose().to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5edf7e2",
   "metadata": {},
   "source": [
    "## More plots\n",
    "\n",
    "Here are some more plots that we can use to analyse our data, but which didn't make it to the paper or the technical appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341d043",
   "metadata": {},
   "source": [
    "### Model size\n",
    "\n",
    "We create the following types of plots:\n",
    "\n",
    "- A square model size comparison with the number of clauses of the GIS encoding on one axis, and the number of constraints of the ILP encoding on the other. The colour indicates $k$, $|V|$, $|E|$, or median degree.\n",
    "- Individual plots, where we compare the number of variables or the number of constraints/clauses for both encodings as a function of $k$ for each instance.\n",
    "- Plots in which we plot the total number of constraint or clauses as a function of $k$, $|V|$, $|E|$ or median degree for each instance in one figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enc_size_square(instances=None, size_param='k', ilp_config='config1'):\n",
    "    \"\"\"Plot model sizes of ILP and GIS encoding, with k, n_nodes, n_edges, or median degree visualised in colour.\n",
    "\n",
    "    Args:\n",
    "        instances (list): A list of instances that we want to include in the plot.\n",
    "        size_param (str): Choose from: {k, n_nodes, n_edges, median_degree}\n",
    "\n",
    "    Returns:\n",
    "        bool: The return value. True for success, False otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the figure\n",
    "    \n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_width, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    cm = plt.cm.get_cmap('viridis_r')\n",
    "\n",
    "    # Extract extreme values\n",
    "    max_size = max(\n",
    "        ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)].n_csts.max(), \n",
    "        gis_enc_data[gis_enc_data['benchmark'].isin(instances)].n_clauses.max())\n",
    "    \n",
    "    number, zeros = get_upper_bound(max_size)\n",
    "    fail_size = ceil(number/10.0) * 10**(zeros+1)\n",
    "    \n",
    "    max_colour = max(\n",
    "        ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)][size_param].max(), \n",
    "        gis_enc_data[gis_enc_data['benchmark'].isin(instances)][size_param].max())\n",
    "    \n",
    "    if size_param in ['n_nodes', 'n_edges']:\n",
    "        number, zeros = get_upper_bound(max_colour)\n",
    "        colour_ub = number * 10**(zeros)\n",
    "    elif size_param == 'k':\n",
    "        colour_ub = 16\n",
    "    \n",
    "    for instance in instances:\n",
    "        ilp_enc_data_inst = ilp_enc_data[\n",
    "            (ilp_enc_data['benchmark'] == instance) &\n",
    "            (ilp_enc_data['ilp_configuration'] == ilp_config)].copy()\n",
    "        gis_enc_data_inst = gis_enc_data[\n",
    "            (gis_enc_data['benchmark'] == instance)].copy()\n",
    "        \n",
    "\n",
    "        # Update values for time out:\n",
    "        ilp_enc_data_inst.n_csts = ilp_enc_data_inst.n_csts.replace(np.nan, fail_size)\n",
    "\n",
    "        # Sort values by k (not really necessary)\n",
    "        ilp_enc_data_inst.sort_values('k', inplace=True)\n",
    "        gis_enc_data_inst.sort_values('k', inplace=True)\n",
    "\n",
    "        if gis_enc_data_inst.empty:\n",
    "            print(f\"No data for {instance}\")\n",
    "            continue\n",
    "\n",
    "        # Extract k values, number of clauses, number of variables\n",
    "        X_ilp = ilp_enc_data_inst['n_csts'].tolist()\n",
    "        Y_gis = gis_enc_data_inst['n_clauses'].tolist()\n",
    "        Z = gis_enc_data_inst[size_param].tolist()\n",
    "        \n",
    "        if np.isnan(Z[0]):\n",
    "            print(f\"No data for {instance}\")\n",
    "            continue\n",
    "\n",
    "        # Plot\n",
    "        sc = ax.scatter(X_ilp, Y_gis, c=Z, marker='x', vmin=0, vmax=colour_ub, cmap=cm, zorder=3)\n",
    "\n",
    "    diag_X = range(0, int(fail_size * 10.3), 100)\n",
    "    diag_Y = diag_X\n",
    "    ax.plot(diag_X, diag_Y, '--', color='0.8', lw=2, zorder=1)\n",
    "\n",
    "    timeout_var = range(0, int(fail_size * 10.3), 100)\n",
    "    timeout_const = [fail_size] * len(timeout_var)\n",
    "    ax.plot(timeout_var, timeout_const, '-', color=style['fail']['c'], lw=2, zorder=2)\n",
    "    ax.plot(timeout_const, timeout_var, '-', color=style['fail']['c'], lw=2, zorder=2)\n",
    "\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel('\\# ILP constraints', fontsize=8)\n",
    "    ax.set_ylabel('\\# GIS clauses', fontsize=8)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "    plt.xlim([8, fail_size * 1.5])\n",
    "    plt.ylim([8, fail_size * 1.5])\n",
    "    ax.set_xticks([x for x in [10, 100, 1000, 10000, 100000, 1000000, 10000000] if x < fail_size*10.3])\n",
    "    ax.set_yticks([x for x in [10, 100, 1000, 10000, 100000, 1000000, 10000000] if x < fail_size*10.3])\n",
    "    tolatex.format_axes(ax)\n",
    "    \n",
    "    # create an axis on the right side of ax. The width of cax will be 5%\n",
    "    # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "    tolatex.format_axes(cax)\n",
    "\n",
    "    cbar = fig.colorbar(sc, cax=cax)\n",
    "    cbar_label = ''\n",
    "    if size_param == 'k':\n",
    "        cbar_label = '$k$'\n",
    "    elif size_param == 'n_nodes':\n",
    "        cbar_label = '$|V|$'\n",
    "    elif size_param == 'n_edges':\n",
    "        cbar_label = '$|E|$'\n",
    "     \n",
    "    if size_param in ['n_nodes', 'n_edges']:\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "        cbar.ax.yaxis.set_offset_position('right')                         \n",
    "        cbar.update_ticks()\n",
    "    elif size_param == 'k':\n",
    "        cbar.set_ticks(sorted(gis_enc_data.k.unique()))\n",
    "    \n",
    "    cbar.set_label(cbar_label)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    figname = f\"{ilp_enc_expid}_{gis_enc_expid}_ilp-{ilp_config}_model-size-vs-{size_param}_square_ijcai\"\n",
    "    plt.savefig(f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{figname}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "instances = relevant_networks\n",
    "plot_enc_size_square(instances=instances, size_param='k', ilp_config='config1')\n",
    "plot_enc_size_square(instances=instances, size_param='n_nodes', ilp_config='config1')\n",
    "plot_enc_size_square(instances=instances, size_param='n_edges', ilp_config='config1')\n",
    "plot_enc_size_square(instances=instances, size_param='k', ilp_config='config0')\n",
    "plot_enc_size_square(instances=instances, size_param='n_nodes', ilp_config='config0')\n",
    "plot_enc_size_square(instances=instances, size_param='n_edges', ilp_config='config0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ilp_enc_size_square(instances=None, size_param='k'):\n",
    "\n",
    "    # Set up the figure\n",
    "    \n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_width, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    cm = plt.cm.get_cmap('viridis_r')\n",
    "\n",
    "    # Extract extreme values\n",
    "    max_size = ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)].n_csts.max()\n",
    "    \n",
    "    number, zeros = get_upper_bound(max_size)\n",
    "    fail_size = ceil(number/10.0) * 10**(zeros+1)\n",
    "    \n",
    "    max_colour = ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)][size_param].max()\n",
    "    \n",
    "    if size_param in ['n_nodes', 'n_edges']:\n",
    "        number, zeros = get_upper_bound(max_colour)\n",
    "        colour_ub = number * 10**(zeros)\n",
    "    elif size_param == 'k':\n",
    "        colour_ub = 16\n",
    "    \n",
    "    for instance in instances:\n",
    "        ilp_enc_data_inst_config0 = ilp_enc_data[\n",
    "            (ilp_enc_data['benchmark'] == instance) &\n",
    "            (ilp_enc_data['ilp_configuration'] == 'config0')].copy()\n",
    "        ilp_enc_data_inst_config1 = ilp_enc_data[\n",
    "            (ilp_enc_data['benchmark'] == instance) &\n",
    "            (ilp_enc_data['ilp_configuration'] == 'config1')].copy()\n",
    "        \n",
    "\n",
    "        # Update values for time out:\n",
    "        ilp_enc_data_inst_config0.n_csts = ilp_enc_data_inst_config0.n_csts.replace(np.nan, fail_size)\n",
    "        ilp_enc_data_inst_config1.n_csts = ilp_enc_data_inst_config1.n_csts.replace(np.nan, fail_size)\n",
    "\n",
    "        # Sort values by k (not really necessary)\n",
    "        ilp_enc_data_inst_config0.sort_values('k', inplace=True)\n",
    "        ilp_enc_data_inst_config1.sort_values('k', inplace=True)\n",
    "        \n",
    "#         if gis_enc_data_inst.empty:\n",
    "#             print(f\"No data for {instance}\")\n",
    "#             continue\n",
    "\n",
    "        # Extract k values, number of clauses, number of variables\n",
    "        X_config0 = ilp_enc_data_inst_config0['n_csts'].tolist()\n",
    "        Y_config1 = ilp_enc_data_inst_config1['n_csts'].tolist()\n",
    "        Z = ilp_enc_data_inst_config0[size_param].tolist()\n",
    "        \n",
    "        if np.isnan(Z[0]):\n",
    "            print(f\"No data for {instance}\")\n",
    "            continue\n",
    "\n",
    "        # Plot\n",
    "        sc = ax.scatter(X_config0, Y_config1, c=Z, marker='x', vmin=0, vmax=colour_ub, cmap=cm, zorder=3)\n",
    "\n",
    "    diag_X = range(0, int(fail_size * 10.3), 100)\n",
    "    diag_Y = diag_X\n",
    "    ax.plot(diag_X, diag_Y, '--', color='0.8', lw=2, zorder=1)\n",
    "\n",
    "    timeout_var = range(0, int(fail_size * 10.3), 100)\n",
    "    timeout_const = [fail_size] * len(timeout_var)\n",
    "    ax.plot(timeout_var, timeout_const, '-', color=style['fail']['c'], lw=2, zorder=2)\n",
    "    ax.plot(timeout_const, timeout_var, '-', color=style['fail']['c'], lw=2, zorder=2)\n",
    "\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel('\\# constraints without removing supersets', fontsize=8)\n",
    "    ax.set_ylabel('\\# constraints with removed supersets', fontsize=8)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "    plt.xlim([8, fail_size * 1.5])\n",
    "    plt.ylim([8, fail_size * 1.5])\n",
    "    ax.set_xticks([x for x in [10, 100, 1000, 10000, 100000, 1000000, 10000000] if x < fail_size*10.3])\n",
    "    ax.set_yticks([x for x in [10, 100, 1000, 10000, 100000, 1000000, 10000000] if x < fail_size*10.3])\n",
    "    tolatex.format_axes(ax)\n",
    "    \n",
    "    # create an axis on the right side of ax. The width of cax will be 5%\n",
    "    # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "    tolatex.format_axes(cax)\n",
    "\n",
    "    cbar = fig.colorbar(sc, cax=cax)\n",
    "    cbar_label = ''\n",
    "    if size_param == 'k':\n",
    "        cbar_label = '$k$'\n",
    "    elif size_param == 'n_nodes':\n",
    "        cbar_label = '$|V|$'\n",
    "    elif size_param == 'n_edges':\n",
    "        cbar_label = '$|E|$'\n",
    "     \n",
    "    if size_param in ['n_nodes', 'n_edges']:\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "        cbar.ax.yaxis.set_offset_position('right')                         \n",
    "        cbar.update_ticks()\n",
    "    elif size_param == 'k':\n",
    "        cbar.set_ticks(sorted(gis_enc_data.k.unique()))\n",
    "    \n",
    "    cbar.set_label(cbar_label)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    figname = f\"{ilp_enc_expid}_model-size-comparison_configs_{size_param}_square_ijcai\"\n",
    "    plt.savefig(f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{figname}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "instances = relevant_networks\n",
    "plot_ilp_enc_size_square(instances=instances, size_param='k')\n",
    "plot_ilp_enc_size_square(instances=instances, size_param='n_nodes')\n",
    "plot_ilp_enc_size_square(instances=instances, size_param='n_edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41fadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_size_vs_k_gis(instances=None):\n",
    "\n",
    "    n_instances = len(instances)\n",
    "    n_cols = 3\n",
    "    n_rows = ceil(n_instances / float(n_cols))\n",
    "    max_n_rows = 5\n",
    "    num_figs = ceil(n_rows / float(max_n_rows))\n",
    "    rows_plotted = 0\n",
    "    \n",
    "    instance_id = 0\n",
    "    \n",
    "    for fig_idx in range(num_figs):\n",
    "        n_rows_in_this_fig = min(max_n_rows, n_rows - rows_plotted)\n",
    "        fig_width = 2*col_width_in + col_gap_in\n",
    "        fig_height = fig_width * 0.25 * n_rows_in_this_fig\n",
    "\n",
    "        tolatex.latexify(fig_width=fig_width, fig_height=fig_height, columns=column)\n",
    "        plt.minorticks_off()\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows_in_this_fig, n_cols)\n",
    "        plt.subplots_adjust(hspace=0.1)\n",
    "        plt.subplots_adjust(wspace=0.1)\n",
    "\n",
    "        for row in axes:\n",
    "            for col in row:\n",
    "                if instance_id >= n_instances:\n",
    "                    break\n",
    "                instance = instances[instance_id]\n",
    "                instance_id += 1\n",
    "                print(instance)\n",
    "                gis_enc_data_inst = gis_enc_data[(gis_enc_data['benchmark'] == instance)].copy()\n",
    "                gis_enc_data_inst.sort_values('k', inplace=True)\n",
    "\n",
    "                if gis_enc_data_inst.empty:\n",
    "                    print(f\"No data for {instance}\")\n",
    "                    continue\n",
    "                n_nodes = gis_enc_data_inst.n_nodes.unique()[0]\n",
    "                if np.isnan(n_nodes):\n",
    "                    print(f\"No data for {instance}\")\n",
    "                    continue\n",
    "\n",
    "                # Extract k values, number of clauses, number of variables\n",
    "                X = gis_enc_data_inst['k'].tolist()\n",
    "                Y_clauses = gis_enc_data_inst['n_clauses'].tolist()\n",
    "                Y_vars = gis_enc_data_inst['n_vars'].tolist()\n",
    "\n",
    "                # Plot\n",
    "                col.plot(X, Y_clauses, lw=1,\n",
    "                         ls=style['gis-clss']['ls'],\n",
    "                         marker=style['gis-clss']['m'],\n",
    "                         color=style['gis-clss']['c'])\n",
    "                \n",
    "                col2 = col.twinx() \n",
    "                col2.plot(X, Y_vars, lw=1,\n",
    "                         ls=style['gis-vars']['ls'],\n",
    "                         marker=style['gis-vars']['m'],\n",
    "                         color=style['gis-vars']['c'])\n",
    "\n",
    "                # Annotations\n",
    "                col.set_title(re.sub('\\.gz|\\.mtx|\\.edges|\\.txt', '', instance), fontsize=8)\n",
    "                col.set_xlabel('$k$', fontsize=8)\n",
    "                col.set_ylabel('\\# clauses', fontsize=8)\n",
    "                col.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "                col.xaxis.set_ticks([int(k) for k in k_values])\n",
    "                \n",
    "                col2.set_ylabel('\\# variables', fontsize=8)\n",
    "                col2.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "\n",
    "                col.text(0.95, 0.1, '$|V|$ = ' + latexify_integer(int(n_nodes)),\n",
    "                         transform=col.transAxes,\n",
    "                         horizontalalignment='right', fontsize=8)\n",
    "                tolatex.format_axes(col)\n",
    "                \n",
    "\n",
    "            rows_plotted += 1\n",
    "            \n",
    "        labels = ['\\# clauses in CNF encoding',\n",
    "                  '\\# variables in CNF encoding']\n",
    "        leg_elts = [\n",
    "            (Line2D([0], [0], label=labels[1], lw=1,\n",
    "                         ls=style['gis-clss']['ls'],\n",
    "                         marker=style['gis-clss']['m'],\n",
    "                         color=style['gis-clss']['c'])),\n",
    "            (Line2D([0], [0], label=labels[0], lw=1,\n",
    "                         ls=style['gis-vars']['ls'],\n",
    "                         marker=style['gis-vars']['m'],\n",
    "                         color=style['gis-vars']['c']))\n",
    "        ]\n",
    "        leg = Legend(fig, handles=leg_elts, labels=labels,\n",
    "                     bbox_to_anchor=(0.5, 0.9175), loc='center', ncol=2, fontsize=8, framealpha=0)\n",
    "        fig.add_artist(leg)\n",
    "        \n",
    "        fig.suptitle(\"Model sizes {\\sc FindGIS}\", fontsize=14)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        figname = f'{gis_enc_expid}_{gis_sol_expid}_n-clauses-and_n-variables-vs-k_{n_instances}-instances_fig{fig_idx}'\n",
    "        fig.savefig(f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "        if save_png:\n",
    "            fig.savefig(f\"{figname}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "        plt.clf()\n",
    "    \n",
    "plot_model_size_vs_k_gis(instances=relevant_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c9e14",
   "metadata": {},
   "source": [
    "### Solving Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410548d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solving_time_square(instances=None, size_param='k', ilp_config='config1'):\n",
    "    \"\"\"Plot solving times for ILP and GIS method, with k, n_nodes, n_edges, or median degree visualised in colour.\n",
    "\n",
    "    Args:\n",
    "        instances (list): A list of instances that we want to include in the plot.\n",
    "        size_param (str): Choose from: {k, n_nodes, n_edges, median_degree}\n",
    "        ilp_config (str): Choose from: {config0, config1}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the figure\n",
    "    \n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_width, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    cm = plt.cm.get_cmap('viridis_r')\n",
    "\n",
    "    # Extract extreme values    \n",
    "    max_colour = max(\n",
    "        ilp_enc_data[ilp_enc_data['benchmark'].isin(instances)][size_param].max(), \n",
    "        gis_enc_data[gis_enc_data['benchmark'].isin(instances)][size_param].max())\n",
    "    \n",
    "    if size_param in ['n_nodes', 'n_edges']:\n",
    "        number, zeros = get_upper_bound(max_colour)\n",
    "        colour_ub = number * 10**(zeros)\n",
    "    elif size_param == 'k':\n",
    "        colour_ub = 16\n",
    "\n",
    "    for instance in instances:\n",
    "        print(instance)\n",
    "        ilp_data_inst = ilp_data[\n",
    "            (ilp_data['benchmark'] == instance) &\n",
    "            (ilp_data['ilp_configuration'] == ilp_config)].copy()\n",
    "        gis_data_inst = gis_data[\n",
    "            (gis_data['benchmark'] == instance)].copy()        \n",
    "        \n",
    "        # Update values of failure:\n",
    "        ilp_data_inst.utime_solve = np.where(\n",
    "            (ilp_data_inst.n_vars.isna()) | (ilp_data_inst.optimised_value.isna()),\n",
    "            sol_timeout, ilp_data_inst.utime_solve)\n",
    "        gis_data_inst.utime_solve = np.where(\n",
    "            (gis_data_inst.n_vars.isna()) | (gis_data_inst.optimised_value < 0),\n",
    "            sol_timeout, gis_data_inst.utime_solve)\n",
    "\n",
    "        # Sort values by k\n",
    "        ilp_data_inst.sort_values('k', inplace=True)\n",
    "        gis_data_inst.sort_values('k', inplace=True)\n",
    "\n",
    "\n",
    "        # Extract k values, number of clauses, number of variables\n",
    "        X_ilp = ilp_data_inst['utime_solve'].tolist() \n",
    "        Y_gis = gis_data_inst['utime_solve'].tolist()\n",
    "        Z = gis_data_inst[size_param].tolist()\n",
    "        \n",
    "        if np.isnan(Z[0]):\n",
    "            print(f\"No data for {instance}.\")\n",
    "            continue\n",
    "\n",
    "        # Plot\n",
    "        sc = ax.scatter(X_ilp, Y_gis, c=Z, marker='x', vmin=0, vmax=colour_ub, cmap=cm, zorder=3)\n",
    "\n",
    "    diag_X = range(0, int(sol_timeout * 1.3), 100)\n",
    "    diag_Y = diag_X\n",
    "    ax.plot(diag_X, diag_Y, '--', color='0.8', lw=2, zorder=1)\n",
    "\n",
    "    timeout_var = range(0, int(sol_timeout * 1.3), 100)\n",
    "    timeout_const = [sol_timeout] * len(timeout_var)\n",
    "    ax.plot(timeout_var, timeout_const, '-', color=style['fail']['c'], lw=2, zorder=2)\n",
    "    ax.plot(timeout_const, timeout_var, '-', color=style['fail']['c'], lw=2, zorder=2)\n",
    "\n",
    "    # create an axes on the right side of ax. The width of cax will be 5%\n",
    "    # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel('solving time ILP [CPU s]', fontsize=8)\n",
    "    ax.set_ylabel('solving time GIS [CPU s]', fontsize=8)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "    plt.xlim([8, sol_timeout * 1.05])\n",
    "    plt.ylim([8, sol_timeout * 1.05])\n",
    "    ax.set_xticks([x for x in [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000] if x < sol_timeout*10.3])\n",
    "    ax.set_yticks([x for x in [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000] if x < sol_timeout*10.3])\n",
    "    tolatex.format_axes(ax)\n",
    "    tolatex.format_axes(cax)\n",
    "\n",
    "    cbar = fig.colorbar(sc, cax=cax)\n",
    "    cbar_label = ''\n",
    "    if size_param == 'k':\n",
    "        cbar_label = '$k$'\n",
    "    elif size_param == 'n_nodes':\n",
    "        cbar_label = '$|V|$'\n",
    "    elif size_param == 'n_edges':\n",
    "        cbar_label = '$|E|$'\n",
    "     \n",
    "    if size_param in ['n_nodes', 'n_edges']:\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "        cbar.ax.yaxis.set_offset_position('right')                         \n",
    "        cbar.update_ticks()\n",
    "    elif size_param == 'k':\n",
    "        cbar.set_ticks(sorted(gis_enc_data.k.unique()))\n",
    "    \n",
    "    cbar.set_label(cbar_label)\n",
    "    fig.tight_layout()\n",
    "    figname = f\"{ilp_enc_expid}_{gis_enc_expid}_solving-time-vs-{size_param}_ilp-{ilp_config}_square_ijcai\"\n",
    "    plt.savefig(f\"{figname}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{figname}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "# instances = ilp_enc_data.benchmark.unique()\n",
    "instances = relevant_networks\n",
    "plot_solving_time_square(instances=instances, size_param='k', ilp_config='config1')\n",
    "plot_solving_time_square(instances=instances, size_param='n_nodes', ilp_config='config1')\n",
    "plot_solving_time_square(instances=instances, size_param='n_edges', ilp_config='config1')\n",
    "plot_enc_size_square(instances=instances, size_param='k', ilp_config='config0')\n",
    "plot_enc_size_square(instances=instances, size_param='n_nodes', ilp_config='config0')\n",
    "plot_enc_size_square(instances=instances, size_param='n_edges', ilp_config='config0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde58c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solving_time_vs_network_size(instances=None, network_size_param='n_nodes'):\n",
    "    \n",
    "    # Set up the figure\n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    fig_height =  fig_width * 0.5\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_height, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('viridis_r')\n",
    "\n",
    "    gis_data_inst = gis_data[(gis_data.benchmark.isin(instances))]\n",
    "\n",
    "    gis_data_inst.utime_solve = np.where(\n",
    "        (gis_data_inst.n_vars.isna()) | (gis_data_inst.optimised_value < 0),\n",
    "        sol_timeout, gis_data_inst.utime_solve)\n",
    "\n",
    "    for k in sorted([int(k) for k in k_values]):\n",
    "        k_data = gis_data_inst[gis_data_inst['k'] == k].copy()\n",
    "        k_data.sort_values(network_size_param, inplace=True)\n",
    "        network_sizes = k_data[network_size_param].to_list()\n",
    "        solving_times = k_data.utime_solve.to_list()\n",
    "\n",
    "#         ax.plot(network_sizes, solving_times,\n",
    "#                 color=cmap(k / 16.0), lw=0.5,\n",
    "#                 label=r'$k = ' + str(k) + r'$')\n",
    "        ax.scatter(network_sizes, solving_times,\n",
    "                color=cmap((k-1) / 16.0), marker='x',\n",
    "                label=r'$k = ' + str(k) + r'$')\n",
    "    max_size = gis_data_inst[network_size_param].max()\n",
    "    x_timeout = range(10, int(10 * max_size), int(max_size/20))\n",
    "    y_timeout = [sol_timeout] * len(x_timeout)\n",
    "    ax.plot(x_timeout, y_timeout, lw=2, c=c_timeout, label='timeout')\n",
    "    \n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    ax.set_xticks([x for x in [10, 100, 1000, 10000, 100000, 1000000] if x < max_size*10.3])\n",
    "    ax.set_xlim((10, 1000000))\n",
    "    \n",
    "    if network_size_param == 'n_nodes':\n",
    "        ax.set_xlabel(r'$|V|$')\n",
    "    elif network_size_param == 'n_edges':\n",
    "        ax.set_xlabel(r'$|E|$')\n",
    "        \n",
    "    ax.set_ylabel(r'solving time [CPU s]')\n",
    "        \n",
    "    tolatex.format_axes(ax)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if len(instances) > 10:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.775, 0.3),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=2,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "    else:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.75, 0.3),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=2,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "\n",
    "    fig_filename = f'{gis_enc_expid}_gis_solving-time_vs_{network_size_param}_ijcai'\n",
    "    plt.savefig(f\"{fig_filename}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{fig_filename}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "instances = gis_enc_data.benchmark.unique()\n",
    "plot_solving_time_vs_network_size(instances=instances, network_size_param='n_nodes')\n",
    "plot_solving_time_vs_network_size(instances=instances, network_size_param='n_edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e1ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solving_cactus_plots(instances=None):\n",
    "    \n",
    "    # Set up the figure\n",
    "    correction = 1.12     # May need this to make the figures actually the right size\n",
    "    fig_width = col_width_in * correction\n",
    "    fig_height =  fig_width * 0.5\n",
    "    tolatex.latexify(fig_width=fig_width, fig_height=fig_height, columns=column)\n",
    "    plt.minorticks_off()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('viridis_r')\n",
    "    markers = ['x', '+', '1', '2', '3', '4']\n",
    "    \n",
    "    gis_data_inst = gis_data[(gis_data.benchmark.isin(instances))]\n",
    "\n",
    "    gis_data_inst.utime_solve = np.where(\n",
    "        (gis_data_inst.n_vars.isna()) | (gis_data_inst.optimised_value < 0),\n",
    "        sol_timeout, gis_data_inst.utime_solve)\n",
    "\n",
    "    for i, k in enumerate(sorted([int(k) for k in k_values])):\n",
    "        k_data = gis_data_inst[gis_data_inst['k'] == k].copy()\n",
    "        k_data.sort_values('utime_solve', inplace=True)\n",
    "        solving_times = k_data.utime_solve.to_list()\n",
    "\n",
    "        ax.plot(range(len(k_data)), solving_times,\n",
    "                color=cmap((k-1) / 16.0), lw=0.5,\n",
    "                label=r'$k = ' + str(k) + r'$',\n",
    "                marker=markers[i % len(markers)],\n",
    "                ms=5)\n",
    "\n",
    "    ax.xaxis.grid(color='0.8', linestyle=':')\n",
    "    ax.yaxis.grid(color='0.8', linestyle=':')\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "\n",
    "        \n",
    "    ax.set_xlabel(r'instances')\n",
    "    ax.set_ylabel(r'solving time [CPU s]')\n",
    "        \n",
    "    tolatex.format_axes(ax)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if len(instances) > 10:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.25, 0.7),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=2,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "    else:\n",
    "        ax.legend(handles[::-1], labels[::-1],\n",
    "                  bbox_to_anchor=(0.25, 0.7),\n",
    "                  loc='center',\n",
    "                  fontsize=7,\n",
    "                  ncol=2,\n",
    "                  labelspacing=0.5,\n",
    "                  columnspacing=0.8)\n",
    "\n",
    "    fig_filename = f'{gis_enc_expid}_gis_cactus-plot_ijcai'\n",
    "    plt.savefig(f\"{fig_filename}.pdf\", bbox_inches=\"tight\")\n",
    "    if save_png:\n",
    "        plt.savefig(f\"{fig_filename}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "instances = gis_enc_data.benchmark.unique()\n",
    "solving_cactus_plots(instances=instances)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd48ca",
   "metadata": {},
   "source": [
    "### Correlation between solving time and network size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff45265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(instances=None):\n",
    "    gis_data_inst = gis_data[gis_data['benchmark'].isin(instances)].copy()\n",
    "    \n",
    "    for k in [int(k_value) for k_value in k_values]:\n",
    "        gis_data_inst_k_solved = gis_data_inst[\n",
    "            (gis_data_inst.k == k) & \n",
    "            (gis_data_inst.optimised_value > -1)].copy()\n",
    "        gis_data_inst_k_solved.sort_values('n_nodes', inplace=True)\n",
    "        \n",
    "        network_sizes = gis_data_inst_k_solved.n_nodes.to_list()\n",
    "        model_sizes = gis_data_inst_k_solved.n_clauses.to_list()\n",
    "        solving_times = gis_data_inst_k_solved.utime_solve.to_list()\n",
    "        \n",
    "        print(k)\n",
    "        print(np.corrcoef(network_sizes, solving_times))\n",
    "    \n",
    "compute_correlations(instances=relevant_networks_social)    \n",
    "compute_correlations(instances=relevant_networks_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076814d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
